{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing iwatobipen JAK3 results with our classifier#\n",
    "    - Matt Robinson\n",
    "\n",
    "https://iwatobipen.wordpress.com/2017/05/18/graph-convolution-classification-with-deepchem/\n",
    "\n",
    "The prolific and well-known chemoinformatics blogger *iwatobipen* released his result using a graph convolutional network using DeepChem. Here we compare his results to those obtained with our own, much simpler gcn.\n",
    "\n",
    "The dataset is JAK3 inhibitor activity data obtained from CHEMBL and availalbe on iwatobipen's github: \n",
    "\n",
    "https://github.com/iwatobipen/deeplearning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../../')\n",
    "\n",
    "import mygcn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mygcn import features\n",
    "from mygcn import gcn\n",
    "from mygcn import train\n",
    "from mygcn import evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import dgl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running our classifier: #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl, valid_dl, test_dl = features.get_graph_data('jak3_activities.csv',\n",
    "                                      smiles_field='CANONICAL_SMILES',\n",
    "                                      labels_field='activity_class',\n",
    "                                      train_size=0.8,\n",
    "                                      valid_size=0.0,\n",
    "                                      self_edges=True,\n",
    "                                      edge_features=True,\n",
    "                                      seed=1) # note results still not totally deterministic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = features.get_num_atom_features() + features.get_num_bond_features()\n",
    "learning_rate = 0.001\n",
    "\n",
    "model = gcn.DeepChemGCNClassifier(n_inputs=num_features,\n",
    "                                 n_hidden=64,\n",
    "                                 n_hidden_layers=2,\n",
    "                                 n_outputs=2,\n",
    "                                 dropout=0.2)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "opt = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note that we will also train for 50 epochs, as is done in the post ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, train loss 0.6568 valid loss N/A\n",
      "Epoch 5, train loss 0.5159 valid loss N/A\n",
      "Epoch 10, train loss 0.4838 valid loss N/A\n",
      "Epoch 15, train loss 0.4855 valid loss N/A\n",
      "Epoch 20, train loss 0.4748 valid loss N/A\n",
      "Epoch 25, train loss 0.4529 valid loss N/A\n",
      "Epoch 30, train loss 0.4292 valid loss N/A\n",
      "Epoch 35, train loss 0.4310 valid loss N/A\n",
      "Epoch 40, train loss 0.4332 valid loss N/A\n",
      "Epoch 45, train loss 0.4322 valid loss N/A\n",
      "CPU times: user 4min 52s, sys: 3.16 s, total: 4min 56s\n",
      "Wall time: 1min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train.fit(model, train_dl, valid_dl, loss_func, opt, n_epochs=50,\n",
    "          report_valid_loss=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss:  0.4343380232652028\n",
      "accuracy:  0.8055555555555556\n",
      "classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.96      0.88       134\n",
      "           1       0.76      0.35      0.48        46\n",
      "\n",
      "   micro avg       0.81      0.81      0.81       180\n",
      "   macro avg       0.79      0.66      0.68       180\n",
      "weighted avg       0.80      0.81      0.78       180\n",
      "\n",
      "roc-auc:  0.7978585334198572\n",
      "bootstrapped roc-auc:  [0.7342825147976324, 0.8557754704737184]\n"
     ]
    }
   ],
   "source": [
    "evaluation.evaluate_classifier(model, test_dl, loss_func)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
