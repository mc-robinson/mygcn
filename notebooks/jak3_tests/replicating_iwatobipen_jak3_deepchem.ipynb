{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replicating iwatobipen JAK3 results with DeepChem#\n",
    "    - Matt Robinson\n",
    "\n",
    "https://iwatobipen.wordpress.com/2017/05/18/graph-convolution-classification-with-deepchem/\n",
    "\n",
    "The prolific and well-known chemoinformatics blogger *iwatobipen* released his result using a graph convolutional network using DeepChem. Here we compare his results to those obtained with our own, much simpler gcn.\n",
    "\n",
    "The dataset is JAK3 inhibitor activity data obtained from CHEMBL and availalbe on iwatobipen's github: \n",
    "\n",
    "https://github.com/iwatobipen/deeplearning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthewrobinson/anaconda/envs/deepchem-env/lib/python2.7/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import deepchem as dc\n",
    "from deepchem.models.tensorgraph.models.graph_models import GraphConvModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading raw samples now.\n",
      "shard_size: 8192\n",
      "About to start loading CSV from ./jak3_activities.csv\n",
      "Loading shard 1 of size 8192.\n",
      "Featurizing sample 0\n",
      "TIMING: featurizing shard 0 took 3.504 s\n",
      "TIMING: dataset construction took 6.570 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 5.421 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 4.324 s\n",
      "Loading dataset from disk.\n"
     ]
    }
   ],
   "source": [
    "graph_featurizer = dc.feat.graph_features.ConvMolFeaturizer()\n",
    "loader = dc.data.data_loader.CSVLoader(tasks=['activity_class'],\n",
    "                                       smiles_field=\"CANONICAL_SMILES\",\n",
    "                                       id_field=\"CMPD_CHEMBLID\",\n",
    "                                       featurizer=graph_featurizer)\n",
    "\n",
    "dataset = loader.featurize('./jak3_activities.csv')\n",
    " \n",
    "splitter = dc.splits.splitters.RandomSplitter()\n",
    "trainset, testset = splitter.train_test_split(dataset, frac_train=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GraphConvModel(n_tasks=1, n_classes=2, mode='classification',\n",
    "                       tensorboard=True,  model_dir='models/',\n",
    "                       dropout=0.2, graph_conv_layers=[64,64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthewrobinson/anaconda/envs/deepchem-env/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.py:98: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('train_loss: ', 52.21642932891846)\n",
      "('train_loss: ', 49.081698870658876)\n",
      "('train_loss: ', 47.03386784791947)\n",
      "('train_loss: ', 47.48215756416321)\n",
      "('train_loss: ', 43.89353243112564)\n",
      "('train_loss: ', 42.1603260755539)\n",
      "('train_loss: ', 40.23352180719375)\n",
      "('train_loss: ', 38.77171133756637)\n",
      "('train_loss: ', 38.65405027866363)\n",
      "('train_loss: ', 36.0815532207489)\n",
      "CPU times: user 6min 24s, sys: 1min 2s, total: 7min 27s\n",
      "Wall time: 6min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# fit for 50 epochs, as in post\n",
    "for _ in range(10):\n",
    "    train_loss = model.fit(trainset, nb_epoch=5)\n",
    "    print('train_loss: ', train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed_metrics: [0.8486111111111111]\n",
      "computed_metrics: [0.9008319940417859]\n",
      "train scores\n",
      "{'mean-roc_auc_score': 0.9008319940417859, 'accuracy_score': 0.8486111111111111}\n"
     ]
    }
   ],
   "source": [
    "train_scores = model.evaluate(\n",
    "                trainset,\n",
    "                [dc.metrics.Metric(dc.metrics.accuracy_score),\n",
    "                 dc.metrics.Metric( dc.metrics.roc_auc_score, np.mean)]\n",
    "                )\n",
    "print('train scores')\n",
    "print(train_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed_metrics: [0.7277777777777777]\n",
      "computed_metrics: [0.7352307692307692]\n",
      "test scores\n",
      "{'mean-roc_auc_score': 0.7352307692307692, 'accuracy_score': 0.7277777777777777}\n"
     ]
    }
   ],
   "source": [
    "test_scores = model.evaluate(\n",
    "                testset,\n",
    "                [dc.metrics.Metric(dc.metrics.accuracy_score),\n",
    "                 dc.metrics.Metric( dc.metrics.roc_auc_score, np.mean)]\n",
    "                )\n",
    "print('test scores')\n",
    "print(test_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_dc_classifier(model, test_ds, classes=[0,1]):\n",
    "    \"evaluate a DeepChem model for classification\"\n",
    "    \n",
    "    from sklearn.metrics import accuracy_score\n",
    "    from sklearn.metrics import classification_report\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    from sklearn.metrics import roc_auc_score, auc, roc_curve\n",
    "    from sklearn.preprocessing import label_binarize\n",
    "    \n",
    "    def bs_roc_auc_score(y_true, y_prob, n_boostraps=1000):\n",
    "        \"code to bootstrap the auc score: copied from Ogrisel's SO answer\"\n",
    "\n",
    "        n_bootstraps = 1000\n",
    "        rng_seed = 42  # control reproducibility\n",
    "        bootstrapped_scores = []\n",
    "\n",
    "        rng = np.random.RandomState(rng_seed)\n",
    "        for i in range(n_bootstraps):\n",
    "            # bootstrap by sampling with replacement on the prediction indices\n",
    "            indices = rng.randint(0, len(y_prob) - 1, len(y_prob))\n",
    "            indices = [int(idx) for idx in indices]\n",
    "            y_true = np.array(y_true)\n",
    "            y_prob = np.array(y_prob)\n",
    "            if len(np.unique(y_true[indices])) < 2:\n",
    "                # We need at least one positive and one negative sample for ROC AUC\n",
    "                # to be defined: reject the sample\n",
    "                continue\n",
    "\n",
    "            score = roc_auc_score(y_true[indices], y_prob[indices])\n",
    "            bootstrapped_scores.append(score)\n",
    "\n",
    "        sorted_scores = np.array(bootstrapped_scores)\n",
    "        sorted_scores.sort()\n",
    "\n",
    "        # Computing the lower and upper bound of the 90% confidence interval\n",
    "        # You can change the bounds percentiles to 0.025 and 0.975 to get\n",
    "        # a 95% confidence interval instead.\n",
    "        confidence_lower = sorted_scores[int(0.05 * len(sorted_scores))]\n",
    "        confidence_upper = sorted_scores[int(0.95 * len(sorted_scores))]\n",
    "        return [confidence_lower, confidence_upper]\n",
    "\n",
    "    y_true = list(testset.y[:,0].astype(int))\n",
    "    \n",
    "    prob_arr = np.array([x[0] for x in model.predict(testset)])\n",
    "    y_pred = list(np.argmax(prob_arr, axis=1))\n",
    "\n",
    "    print('accuracy: ', accuracy_score(y_true, y_pred))\n",
    "    print('classification report: ')\n",
    "    print(classification_report(y_true, y_pred))\n",
    "\n",
    "    if len(classes) == 2:\n",
    "        y_prob = list(prob_arr[:,-1])\n",
    "        print('roc-auc: ', roc_auc_score(y_true, y_prob))\n",
    "        print('bootstrapped roc-auc: ', bs_roc_auc_score(y_true, y_prob))\n",
    "\n",
    "    else:\n",
    "        y_test = label_binarize(y_true, classes=classes)\n",
    "        n_classes = y_test.shape[1]\n",
    "\n",
    "        # Compute ROC curve and ROC area for each class\n",
    "        fpr = dict()\n",
    "        tpr = dict()\n",
    "        roc_auc = dict()\n",
    "        bs_roc_auc = dict()\n",
    "        for i in range(n_classes):\n",
    "            fpr[i], tpr[i], _ = roc_curve(y_test[:, i], prob_arr[:, i])\n",
    "            roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "            bs_roc_auc[i] = bs_roc_auc_score(y_test[:, i], prob_arr[:, i])\n",
    "        \n",
    "        fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), prob_arr.ravel())\n",
    "        roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "        bs_roc_auc['micro'] = bs_roc_auc_score(y_test.ravel(), prob_arr.ravel())\n",
    "\n",
    "        print(\"micro auc score and score for each class: \")\n",
    "        for key in roc_auc:\n",
    "            print(key,' : ', roc_auc[key])\n",
    "        print(\"bootstrapped micro auc score and score for each class: \")\n",
    "        for key in bs_roc_auc:\n",
    "            print(key,' : ', bs_roc_auc[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('accuracy: ', 0.7277777777777777)\n",
      "classification report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.91      0.83       130\n",
      "          1       0.52      0.26      0.35        50\n",
      "\n",
      "avg / total       0.69      0.73      0.69       180\n",
      "\n",
      "('roc-auc: ', 0.7352307692307692)\n",
      "('bootstrapped roc-auc: ', [0.6692913385826772, 0.8013001695873375])\n"
     ]
    }
   ],
   "source": [
    "evaluate_dc_classifier(model, testset, classes=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('train_loss: ', 35.518444657325745)\n",
      "('train_loss: ', 34.883203136920926)\n",
      "('train_loss: ', 32.570836985111235)\n",
      "('train_loss: ', 33.2912921667099)\n",
      "('train_loss: ', 31.446497976779938)\n",
      "('train_loss: ', 30.657007586956023)\n",
      "('train_loss: ', 29.75057816505432)\n",
      "('train_loss: ', 28.672795355319977)\n",
      "('train_loss: ', 27.94592696428299)\n",
      "('train_loss: ', 26.42917002439499)\n",
      "('train_loss: ', 27.486838233470916)\n",
      "('train_loss: ', 26.633309388160704)\n",
      "('train_loss: ', 25.24140247106552)\n",
      "('train_loss: ', 24.68913254737854)\n",
      "('train_loss: ', 5.514284610748291)\n",
      "('train_loss: ', 23.650760960578918)\n",
      "('train_loss: ', 22.06888137459755)\n",
      "('train_loss: ', 21.34109171628952)\n",
      "('train_loss: ', 20.93572798371315)\n",
      "('train_loss: ', 20.26791494488716)\n",
      "CPU times: user 12min 12s, sys: 2min 1s, total: 14min 14s\n",
      "Wall time: 13min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# train for additional 100 epochs\n",
    "for _ in range(20):\n",
    "    train_loss = model.fit(trainset, nb_epoch=5)\n",
    "    print('train_loss: ', train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed_metrics: [0.9291666666666667]\n",
      "computed_metrics: [0.9850505664223276]\n",
      "train scores\n",
      "{'mean-roc_auc_score': 0.9850505664223276, 'accuracy_score': 0.9291666666666667}\n"
     ]
    }
   ],
   "source": [
    "train_scores = model.evaluate(\n",
    "                trainset,\n",
    "                [dc.metrics.Metric(dc.metrics.accuracy_score),\n",
    "                 dc.metrics.Metric( dc.metrics.roc_auc_score, np.mean)]\n",
    "                )\n",
    "print('train scores')\n",
    "print(train_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed_metrics: [0.7555555555555555]\n",
      "computed_metrics: [0.7764615384615385]\n",
      "test scores\n",
      "{'mean-roc_auc_score': 0.7764615384615385, 'accuracy_score': 0.7555555555555555}\n"
     ]
    }
   ],
   "source": [
    "test_scores = model.evaluate(\n",
    "                testset,\n",
    "                [dc.metrics.Metric(dc.metrics.accuracy_score),\n",
    "                 dc.metrics.Metric( dc.metrics.roc_auc_score, np.mean)]\n",
    "                )\n",
    "print('test scores')\n",
    "print(test_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('accuracy: ', 0.7555555555555555)\n",
      "classification report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.92      0.84       130\n",
      "          1       0.61      0.34      0.44        50\n",
      "\n",
      "avg / total       0.73      0.76      0.73       180\n",
      "\n",
      "('roc-auc: ', 0.7764615384615384)\n",
      "('bootstrapped roc-auc: ', [0.7159024103468548, 0.8395388689827076])\n"
     ]
    }
   ],
   "source": [
    "evaluate_dc_classifier(model, testset, classes=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (deepchem-env)",
   "language": "python",
   "name": "deepchem-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
