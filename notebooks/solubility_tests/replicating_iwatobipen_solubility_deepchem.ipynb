{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replicating iwatobipen solubility results with DeepChem #\n",
    "    - Matt Robinson\n",
    "\n",
    "https://iwatobipen.wordpress.com/2019/02/01/try-gcn-qspr-with-pytorch-based-graph-library-rdkit-pytorch-dgl/\n",
    "\n",
    "The prolific and well-known chemoinformatics blogger *iwatobipen* released his result using a graph convolutional network similarly built with pytorch and dgl. Here we compare his results to those obtained with our own gcn built with pytorch and gcn. Our gcn is built includes a few more features somewhat emulating the structure of the DeepChem gcn.\n",
    "\n",
    "The dataset is a solubility dataset available directly from RDKIT. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthewrobinson/anaconda/envs/deepchem-env/lib/python2.7/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import deepchem as dc\n",
    "from deepchem.models.tensorgraph.models.graph_models import GraphConvModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import RDConfig\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "solcls = {'(A) low':0, '(B) medium':1, '(C) high':2} # note the 3 classes\n",
    "\n",
    "train_mols = [m for m in Chem.SDMolSupplier(os.path.join(RDConfig.RDDocsDir,'Book/data/solubility.train.sdf'))]\n",
    "train_smiles = [Chem.MolToSmiles(x) for x in train_mols]\n",
    "train_y = [solcls[m.GetProp('SOL_classification')] for m in train_mols]\n",
    "\n",
    "test_mols = [m for m in Chem.SDMolSupplier(os.path.join(RDConfig.RDDocsDir,'Book/data/solubility.test.sdf'))]\n",
    "test_smiles = [Chem.MolToSmiles(x) for x in test_mols]\n",
    "test_y = [solcls[m.GetProp('SOL_classification')] for m in test_mols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset_df = pd.DataFrame({'smiles': train_smiles, 'labels': train_y})\n",
    "trainset_df.to_csv('solubility_classification_train.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset_df = pd.DataFrame({'smiles': test_smiles, 'labels': test_y})\n",
    "testset_df.to_csv('solubility_classification_test.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('training set size: ', 1025)\n",
      "('testing_set_size: ', 257)\n"
     ]
    }
   ],
   "source": [
    "print('training set size: ', len(train_smiles))\n",
    "print('testing_set_size: ', len(test_smiles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading raw samples now.\n",
      "shard_size: 8192\n",
      "About to start loading CSV from ./solubility_classification_train.csv\n",
      "Loading shard 1 of size 8192.\n",
      "Featurizing sample 0\n",
      "Featurizing sample 1000\n",
      "TIMING: featurizing shard 0 took 1.672 s\n",
      "TIMING: dataset construction took 3.960 s\n",
      "Loading dataset from disk.\n",
      "Loading raw samples now.\n",
      "shard_size: 8192\n",
      "About to start loading CSV from ./solubility_classification_test.csv\n",
      "Loading shard 1 of size 8192.\n",
      "Featurizing sample 0\n",
      "TIMING: featurizing shard 0 took 0.396 s\n",
      "TIMING: dataset construction took 0.973 s\n",
      "Loading dataset from disk.\n"
     ]
    }
   ],
   "source": [
    "graph_featurizer = dc.feat.graph_features.ConvMolFeaturizer()\n",
    "loader = dc.data.data_loader.CSVLoader(tasks=['labels'],\n",
    "                                       smiles_field=\"smiles\",\n",
    "                                       featurizer=graph_featurizer)\n",
    "\n",
    "trainset = loader.featurize('./solubility_classification_train.csv')\n",
    "testset = loader.featurize('./solubility_classification_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GraphConvModel(n_tasks=1, n_classes=len(solcls), mode='classification',\n",
    "                       tensorboard=True,  model_dir='solubility_models/',\n",
    "                       dropout=0.2, graph_conv_layers=[64,64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthewrobinson/anaconda/envs/deepchem-env/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.py:98: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('train_loss: ', 85.43233614834872)\n",
      "('train_loss: ', 66.33962163058195)\n",
      "('train_loss: ', 57.29524721665816)\n",
      "('train_loss: ', 50.515527257052334)\n",
      "('train_loss: ', 45.40156693892045)\n",
      "('train_loss: ', 42.42582628076727)\n",
      "('train_loss: ', 38.53086421272972)\n",
      "('train_loss: ', 35.42941387349909)\n",
      "('train_loss: ', 33.07965602007779)\n",
      "('train_loss: ', 30.58448325070468)\n",
      "('train_loss: ', 28.680832316658712)\n",
      "('train_loss: ', 26.97158300226385)\n",
      "('train_loss: ', 25.668372518366034)\n",
      "('train_loss: ', 23.405790814486416)\n",
      "('train_loss: ', 23.75758847323331)\n",
      "('train_loss: ', 21.848122774470937)\n",
      "('train_loss: ', 21.01615975553339)\n",
      "('train_loss: ', 20.152980336275967)\n",
      "('train_loss: ', 17.974479846332382)\n",
      "('train_loss: ', 17.96369844783436)\n",
      "CPU times: user 12min 19s, sys: 1min 55s, total: 14min 14s\n",
      "Wall time: 11min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# fit for 100 epochs\n",
    "for _ in range(20):\n",
    "    train_loss = model.fit(trainset, nb_epoch=5)\n",
    "    print('train_loss: ', train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed_metrics: [0.9014634146341464]\n",
      "train scores\n",
      "{'accuracy_score': 0.9014634146341464}\n"
     ]
    }
   ],
   "source": [
    "train_scores = model.evaluate(\n",
    "                trainset,\n",
    "                [dc.metrics.Metric(dc.metrics.accuracy_score)]\n",
    "                )\n",
    "print('train scores')\n",
    "print(train_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed_metrics: [0.7704280155642024]\n",
      "test scores\n",
      "{'accuracy_score': 0.7704280155642024}\n"
     ]
    }
   ],
   "source": [
    "test_scores = model.evaluate(\n",
    "                testset,\n",
    "                [dc.metrics.Metric(dc.metrics.accuracy_score)]\n",
    "                )\n",
    "print('test scores')\n",
    "print(test_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_dc_classifier(model, test_ds, classes=[0,1]):\n",
    "    \"evaluate a DeepChem model for classification\"\n",
    "    \n",
    "    from sklearn.metrics import accuracy_score\n",
    "    from sklearn.metrics import classification_report\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    from sklearn.metrics import roc_auc_score, auc, roc_curve\n",
    "    from sklearn.preprocessing import label_binarize\n",
    "    \n",
    "    def bs_roc_auc_score(y_true, y_prob, n_boostraps=1000):\n",
    "        \"code to bootstrap the auc score: copied from Ogrisel's SO answer\"\n",
    "\n",
    "        n_bootstraps = 1000\n",
    "        rng_seed = 42  # control reproducibility\n",
    "        bootstrapped_scores = []\n",
    "\n",
    "        rng = np.random.RandomState(rng_seed)\n",
    "        for i in range(n_bootstraps):\n",
    "            # bootstrap by sampling with replacement on the prediction indices\n",
    "            indices = rng.randint(0, len(y_prob) - 1, len(y_prob))\n",
    "            indices = [int(idx) for idx in indices]\n",
    "            y_true = np.array(y_true)\n",
    "            y_prob = np.array(y_prob)\n",
    "            if len(np.unique(y_true[indices])) < 2:\n",
    "                # We need at least one positive and one negative sample for ROC AUC\n",
    "                # to be defined: reject the sample\n",
    "                continue\n",
    "\n",
    "            score = roc_auc_score(y_true[indices], y_prob[indices])\n",
    "            bootstrapped_scores.append(score)\n",
    "\n",
    "        sorted_scores = np.array(bootstrapped_scores)\n",
    "        sorted_scores.sort()\n",
    "\n",
    "        # Computing the lower and upper bound of the 90% confidence interval\n",
    "        # You can change the bounds percentiles to 0.025 and 0.975 to get\n",
    "        # a 95% confidence interval instead.\n",
    "        confidence_lower = sorted_scores[int(0.05 * len(sorted_scores))]\n",
    "        confidence_upper = sorted_scores[int(0.95 * len(sorted_scores))]\n",
    "        return [confidence_lower, confidence_upper]\n",
    "\n",
    "    y_true = list(testset.y[:,0].astype(int))\n",
    "    \n",
    "    prob_arr = np.array([x[0] for x in model.predict(testset)])\n",
    "    y_pred = list(np.argmax(prob_arr, axis=1))\n",
    "\n",
    "    print('accuracy: ', accuracy_score(y_true, y_pred))\n",
    "    print('classification report: ')\n",
    "    print(classification_report(y_true, y_pred))\n",
    "\n",
    "    if len(classes) == 2:\n",
    "        y_prob = list(prob_arr[:,-1])\n",
    "        print('roc-auc: ', roc_auc_score(y_true, y_prob))\n",
    "        print('bootstrapped roc-auc: ', bs_roc_auc_score(y_true, y_prob))\n",
    "\n",
    "    else:\n",
    "        y_test = label_binarize(y_true, classes=classes)\n",
    "        n_classes = y_test.shape[1]\n",
    "\n",
    "        # Compute ROC curve and ROC area for each class\n",
    "        fpr = dict()\n",
    "        tpr = dict()\n",
    "        roc_auc = dict()\n",
    "        bs_roc_auc = dict()\n",
    "        for i in range(n_classes):\n",
    "            fpr[i], tpr[i], _ = roc_curve(y_test[:, i], prob_arr[:, i])\n",
    "            roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "            bs_roc_auc[i] = bs_roc_auc_score(y_test[:, i], prob_arr[:, i])\n",
    "        \n",
    "        fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), prob_arr.ravel())\n",
    "        roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "        bs_roc_auc['micro'] = bs_roc_auc_score(y_test.ravel(), prob_arr.ravel())\n",
    "\n",
    "        print(\"micro auc score and score for each class: \")\n",
    "        for key in roc_auc:\n",
    "            print(key,' : ', roc_auc[key])\n",
    "        print(\"bootstrapped micro auc score and score for each class: \")\n",
    "        for key in bs_roc_auc:\n",
    "            print(key,' : ', bs_roc_auc[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('accuracy: ', 0.7704280155642024)\n",
      "classification report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.71      0.80       102\n",
      "          1       0.73      0.77      0.75       115\n",
      "          2       0.66      0.95      0.78        40\n",
      "\n",
      "avg / total       0.79      0.77      0.77       257\n",
      "\n",
      "micro auc score and score for each class: \n",
      "(0, ' : ', 0.9384566729917774)\n",
      "(1, ' : ', 0.8349663196570728)\n",
      "(2, ' : ', 0.9705069124423963)\n",
      "('micro', ' : ', 0.9161153083316931)\n",
      "bootstrapped micro auc score and score for each class: \n",
      "(0, ' : ', [0.9131093544137022, 0.9581406972385355])\n",
      "(1, ' : ', [0.7892857142857144, 0.8744976251370113])\n",
      "(2, ' : ', [0.9526205450733752, 0.9853820598006644])\n",
      "('micro', ' : ', [0.8999318710288956, 0.9313243761996162])\n"
     ]
    }
   ],
   "source": [
    "evaluate_dc_classifier(model, testset, classes=[0,1,2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (deepchem-env)",
   "language": "python",
   "name": "deepchem-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
