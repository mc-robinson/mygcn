{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing iwatobipen solubility results with our classifier#\n",
    "    - Matt Robinson\n",
    "\n",
    "https://iwatobipen.wordpress.com/2019/02/01/try-gcn-qspr-with-pytorch-based-graph-library-rdkit-pytorch-dgl/\n",
    "\n",
    "The prolific and well-known chemoinformatics blogger *iwatobipen* released his result using a graph convolutional network similarly built with pytorch and dgl. Here we compare his results to those obtained with our own gcn built with pytorch and gcn. Our gcn is built includes a few more features somewhat emulating the structure of the DeepChem gcn.\n",
    "\n",
    "The dataset is a solubility dataset available directly from RDKIT. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import mygcn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mygcn import features\n",
    "from mygcn import gcn\n",
    "from mygcn import train\n",
    "from mygcn import evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import dgl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import RDConfig\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the Data: #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "solcls = {'(A) low':0, '(B) medium':1, '(C) high':2} # note the 3 classes\n",
    "\n",
    "train_mols = [m for m in Chem.SDMolSupplier(os.path.join(RDConfig.RDDocsDir,'Book/data/solubility.train.sdf'))]\n",
    "train_smiles = [Chem.MolToSmiles(x) for x in train_mols]\n",
    "train_y = [solcls[m.GetProp('SOL_classification')] for m in train_mols]\n",
    "\n",
    "test_mols = [m for m in Chem.SDMolSupplier(os.path.join(RDConfig.RDDocsDir,'Book/data/solubility.test.sdf'))]\n",
    "test_smiles = [Chem.MolToSmiles(x) for x in test_mols]\n",
    "test_y = [solcls[m.GetProp('SOL_classification')] for m in test_mols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset_df = pd.DataFrame({'smiles': train_smiles, 'labels': train_y})\n",
    "trainset_df.to_csv('solubility_classification_train.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset_df = pd.DataFrame({'smiles': test_smiles, 'labels': test_y})\n",
    "testset_df.to_csv('solubility_classification_test.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set size:  1025\n",
      "testing_set_size:  257\n"
     ]
    }
   ],
   "source": [
    "print('training set size: ', len(train_smiles))\n",
    "print('testing_set_size: ', len(test_smiles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl, valid_dl, _ = features.get_graph_data('solubility_classification_train.csv',\n",
    "                                      smiles_field='smiles',\n",
    "                                      labels_field='labels',\n",
    "                                      train_size=1.0,\n",
    "                                      valid_size=0.0,\n",
    "                                      self_edges=True,\n",
    "                                      edge_features=True,\n",
    "                                      seed=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note the use of the function here, since the train/test sets are\n",
    "# already split for us\n",
    "test_dl, _, _ = features.get_graph_data('solubility_classification_test.csv',\n",
    "                                    smiles_field='smiles',\n",
    "                                    labels_field='labels',\n",
    "                                    train_size=1.0,\n",
    "                                    valid_size=0.0,\n",
    "                                    self_edges=True,\n",
    "                                    edge_features=True,\n",
    "                                    seed=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create our DeepChem-like model #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = features.get_num_atom_features() + features.get_num_bond_features()\n",
    "learning_rate = 0.001\n",
    "\n",
    "model = gcn.DeepChemGCNClassifier(n_inputs=num_features,\n",
    "                                 n_hidden=64,\n",
    "                                 n_hidden_layers=2,\n",
    "                                 n_outputs=len(solcls),\n",
    "                                 dropout=0.2)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "opt = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepChemGCNClassifier(\n",
      "  (dropout): Dropout(p=0.2)\n",
      "  (layers): ModuleList(\n",
      "    (0): GraphConvLayer(\n",
      "      (linear): Linear(in_features=73, out_features=64, bias=True)\n",
      "    )\n",
      "    (1): BatchNormLayer(\n",
      "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): GraphPoolLayer()\n",
      "    (3): GraphConvLayer(\n",
      "      (linear): Linear(in_features=64, out_features=64, bias=True)\n",
      "    )\n",
      "    (4): BatchNormLayer(\n",
      "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (5): GraphPoolLayer()\n",
      "  )\n",
      "  (dense_layer): Linear(in_features=64, out_features=128, bias=True)\n",
      "  (final_bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (classification_layer): Linear(in_features=128, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note that we will train for only 100 epochs, not 200 as is done in the post ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, train loss 1.0255 valid loss N/A\n",
      "Epoch 10, train loss 0.5751 valid loss N/A\n",
      "Epoch 20, train loss 0.4999 valid loss N/A\n",
      "Epoch 30, train loss 0.4531 valid loss N/A\n",
      "Epoch 40, train loss 0.4356 valid loss N/A\n",
      "Epoch 50, train loss 0.4782 valid loss N/A\n",
      "Epoch 60, train loss 0.5086 valid loss N/A\n",
      "Epoch 70, train loss 0.3796 valid loss N/A\n",
      "Epoch 80, train loss 0.3616 valid loss N/A\n",
      "Epoch 90, train loss 0.4538 valid loss N/A\n",
      "CPU times: user 7min 42s, sys: 1.46 s, total: 7min 43s\n",
      "Wall time: 2min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Note no validation set in this case, matching iwatobipen's training\n",
    "# valid_dl is just an empty dataloader\n",
    "train.fit(model, train_dl, valid_dl, loss_func, opt, n_epochs=100,\n",
    "          report_valid_loss=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss:  0.7727183434698317\n",
      "accuracy:  0.7704280155642024\n",
      "classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.81      0.83       102\n",
      "           1       0.77      0.69      0.73       115\n",
      "           2       0.64      0.90      0.75        40\n",
      "\n",
      "   micro avg       0.77      0.77      0.77       257\n",
      "   macro avg       0.75      0.80      0.77       257\n",
      "weighted avg       0.78      0.77      0.77       257\n",
      "\n",
      "micro auc score and score for each class: \n",
      "0  :  0.9412397216951297\n",
      "1  :  0.854745866503368\n",
      "2  :  0.9653225806451614\n",
      "micro  :  0.9157822222895123\n",
      "bootstrapped micro auc score and score for each class: \n",
      "0  :  [0.9200371057513915, 0.9603898538048232]\n",
      "1  :  [0.8149020580213241, 0.8895757575757576]\n",
      "2  :  [0.9398275862068965, 0.985309017223911]\n",
      "micro  :  [0.9008986136115342, 0.9312849578641211]\n"
     ]
    }
   ],
   "source": [
    "evaluation.evaluate_classifier(model, test_dl, loss_func, classes=[0,1,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now run our Duvenaud-like model: #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = features.get_num_atom_features() + features.get_num_bond_features()\n",
    "learning_rate = 0.01 # note change here\n",
    "\n",
    "model = gcn.DuvenaudGCNClassifier(n_inputs=num_features,\n",
    "                                  n_hidden=64,\n",
    "                                  n_outputs=len(solcls),)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "opt = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, train loss 1.0025 valid loss N/A\n",
      "Epoch 20, train loss 0.8868 valid loss N/A\n",
      "Epoch 40, train loss 0.8657 valid loss N/A\n",
      "Epoch 60, train loss 0.8614 valid loss N/A\n",
      "Epoch 80, train loss 0.8436 valid loss N/A\n",
      "Epoch 100, train loss 0.8968 valid loss N/A\n",
      "Epoch 120, train loss 0.8627 valid loss N/A\n",
      "Epoch 140, train loss 0.8423 valid loss N/A\n",
      "Epoch 160, train loss 0.8665 valid loss N/A\n",
      "Epoch 180, train loss 0.8675 valid loss N/A\n",
      "CPU times: user 6min 23s, sys: 1.82 s, total: 6min 25s\n",
      "Wall time: 2min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train.fit(model, train_dl, valid_dl, loss_func, opt, n_epochs=200,\n",
    "          report_valid_loss=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss:  0.8723989990022447\n",
      "accuracy:  0.622568093385214\n",
      "classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.66      0.68       102\n",
      "           1       0.59      0.60      0.59       115\n",
      "           2       0.52      0.60      0.56        40\n",
      "\n",
      "   micro avg       0.62      0.62      0.62       257\n",
      "   macro avg       0.61      0.62      0.61       257\n",
      "weighted avg       0.63      0.62      0.62       257\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluation.evaluate_classifier(model, test_dl, loss_func, multiclass=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
